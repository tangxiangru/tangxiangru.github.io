<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="google-site-verification" content="googleb849f8ce9353f945.html" />













  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="欢迎戳进" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="多轮对话:should have Better objective functions and evaluation metrics">
<meta property="og:type" content="article">
<meta property="og:title" content="暑期工作icst">
<meta property="og:url" content="http://yoursite.com/2018/06/30/暑期工作icst/index.html">
<meta property="og:site_name" content="唐相儒的博客">
<meta property="og:description" content="多轮对话:should have Better objective functions and evaluation metrics">
<meta property="og:updated_time" content="2018-08-24T03:13:09.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="暑期工作icst">
<meta name="twitter:description" content="多轮对话:should have Better objective functions and evaluation metrics">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/06/30/暑期工作icst/"/>





  <title> 暑期工作icst | 唐相儒的博客 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">唐相儒的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/首页" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-ban"></i> <br />
            
            博客首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-hand-peace-o"></i> <br />
            
            文章分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/目录" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            文章归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/标签" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sign-language"></i> <br />
            
            文章标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-map-o"></i> <br />
            
            导航
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404.html" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-asl-interpreting"></i> <br />
            
            team
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/06/30/暑期工作icst/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="唐相儒">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ooo.0o0.ooo/2017/07/01/59575381605d5.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="唐相儒的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                暑期工作icst
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-06-30T22:10:49+08:00">
                2018-06-30
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/06/30/暑期工作icst/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/06/30/暑期工作icst/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>多轮对话:should have Better objective functions and evaluation metrics</p>
<a id="more"></a>
<h1 id="1-Neural-Responding-Machine-for-Short-Text-Conversation"><a href="#1-Neural-Responding-Machine-for-Short-Text-Conversation" class="headerlink" title="1.Neural Responding Machine for Short-Text Conversation"></a>1.Neural Responding Machine for Short-Text Conversation</h1><p>2015较老<br>data: 微博数据, 每句限长140个字。每条微博有平均20条回复，共约22w个微博，也就是约440w条问答对。<br>方法：带attention的seq2seq翻译模型</p>
<h1 id="2-Building-End-To-End-Dialogue-Systems-Using-Generative-Hierarchical-Neural-Network-Models"><a href="#2-Building-End-To-End-Dialogue-Systems-Using-Generative-Hierarchical-Neural-Network-Models" class="headerlink" title="2.Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models"></a>2.Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models</h1><p>2016 AAAI</p>
<p>For me there are two main takeaways. First, the use of a hierarchy of RNNs using one to model the sequence of utterances in the dialogue, and one to model the sequences of tokens in an individual turn. And secondly the value of bootstrapping the model using external data, which makes a significant difference to model performance.</p>
<p>utterance是某轮里面的某个人的话，tokens就是word。然后web query任务就是那种百度上搜一个问题他直接给你回复了，我想起来了，这种任务实质就是阅读理解任务。然后boostrap是分为两个，一个是用一个大规模的word embed，可以让他会更多的词，另一个方面就是在另一个非对话数据集上pretrain，让他会说话</p>
<h1 id="2-A-Hierarchical-Latent-Variable-Encoder-Decoder-Model-for-Generating-Dialogues"><a href="#2-A-Hierarchical-Latent-Variable-Encoder-Decoder-Model-for-Generating-Dialogues" class="headerlink" title="2.A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues"></a>2.A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues</h1><p>引入随机隐变量来刻画utterance之间的关系</p>
<h1 id="3-Hierarchical-recurrent-attention-network-for-response-generation"><a href="#3-Hierarchical-recurrent-attention-network-for-response-generation" class="headerlink" title="3.Hierarchical recurrent attention network for response generation."></a>3.Hierarchical recurrent attention network for response generation.</h1><p> extended the hierarchical structure with the attention mechanism [2] to at- tend to important parts within and among utterances with word level attention and utterance level attention, respectively.</p>
<h1 id="4-Multiresolution-Recurrent-Neural-Networks-An-Application-to-Dialogue-Response-Generation"><a href="#4-Multiresolution-Recurrent-Neural-Networks-An-Application-to-Dialogue-Response-Generation" class="headerlink" title="4.Multiresolution Recurrent Neural Networks: An Application to Dialogue Response Generation"></a>4.Multiresolution Recurrent Neural Networks: An Application to Dialogue Response Generation</h1><h1 id="5-AN-ABSTRACTIVE-APPROACH-TO-QUESTION-ANSWERING"><a href="#5-AN-ABSTRACTIVE-APPROACH-TO-QUESTION-ANSWERING" class="headerlink" title="5.AN ABSTRACTIVE APPROACH TO QUESTION ANSWERING"></a>5.AN ABSTRACTIVE APPROACH TO QUESTION ANSWERING</h1><h1 id="6-Query-and-Output-Generating-Words-by-Querying-Distributed-Word-Representations-for-Paraphrase-Generation"><a href="#6-Query-and-Output-Generating-Words-by-Querying-Distributed-Word-Representations-for-Paraphrase-Generation" class="headerlink" title="6.Query and Output: Generating Words by Querying Distributed Word Representations for Paraphrase Generation"></a>6.Query and Output: Generating Words by Querying Distributed Word Representations for Paraphrase Generation</h1><h1 id="7-2017AAAITopic-Aware-Neural-Response-Generation"><a href="#7-2017AAAITopic-Aware-Neural-Response-Generation" class="headerlink" title="7.2017AAAITopic Aware Neural Response Generation"></a>7.2017AAAITopic Aware Neural Response Generation</h1><h1 id="8-How-to-Make-Context-More-Useful-An-Empirical-Study-on-Context-Aware-Neural-Conversational-Models"><a href="#8-How-to-Make-Context-More-Useful-An-Empirical-Study-on-Context-Aware-Neural-Conversational-Models" class="headerlink" title="8.How to Make Context More Useful?An Empirical Study on Context-Aware Neural Conversational Models"></a>8.How to Make Context More Useful?An Empirical Study on Context-Aware Neural Conversational Models</h1><h1 id="统计行数方法"><a href="#统计行数方法" class="headerlink" title="统计行数方法"></a>统计行数方法</h1><p>wc -l</p>
<h1 id="统计轮数方法"><a href="#统计轮数方法" class="headerlink" title="统计轮数方法"></a>统计轮数方法</h1><p>4244675/492065= 8.6262485647 </p>
<p>#AAAI2018对话相关</p>
<h3 id="Dialogue-Act-Sequence-Labeling-Using-Hierarchical-Encoder-with-CRF"><a href="#Dialogue-Act-Sequence-Labeling-Using-Hierarchical-Encoder-with-CRF" class="headerlink" title="Dialogue Act Sequence Labeling Using Hierarchical Encoder with CRF"></a>Dialogue Act Sequence Labeling Using Hierarchical Encoder with CRF</h3><p>In some approaches, a hierarchical convolutional and recurrent neural encoder model are used to learn utterance representations by processing a whole conversation. The utterance representations are further used to classify DA classes using the conditional random field (CRF) as a linear classifier. However, these models might fail in a dialogue system where one can perceive the past utterances, but cannot see future ones.</p>
<p>任务叫Dialogue Act recognition，就是用rnn把句子表示之后放进crf做序列标注</p>
<h3 id="Eliciting-Positive-Emotion-through-Affect-Sensitive-Dialogue-Response-Generation-A-Neural-Network-Approach"><a href="#Eliciting-Positive-Emotion-through-Affect-Sensitive-Dialogue-Response-Generation-A-Neural-Network-Approach" class="headerlink" title="Eliciting Positive Emotion through Affect-Sensitive Dialogue Response Generation: A Neural Network Approach"></a>Eliciting Positive Emotion through Affect-Sensitive Dialogue Response Generation: A Neural Network Approach</h3><p>生成式回复</p>
<h3 id="Augmenting-End-to-End-Dialogue-Systems-with-Commonsense-Knowledge"><a href="#Augmenting-End-to-End-Dialogue-Systems-with-Commonsense-Knowledge" class="headerlink" title="Augmenting End-to-End Dialogue Systems with Commonsense Knowledge"></a>Augmenting End-to-End Dialogue Systems with Commonsense Knowledge</h3><h3 id="Improving-Variational-Encoder-Decoders-in-Dialogue-Generation"><a href="#Improving-Variational-Encoder-Decoders-in-Dialogue-Generation" class="headerlink" title="Improving Variational Encoder-Decoders in Dialogue Generation"></a>Improving Variational Encoder-Decoders in Dialogue Generation</h3><p>Varitional encoder-decoder (VED)已经被广泛应用于对话生成，但与用于编码和解码的强大RNN结构，隐向量分布通常由一个简单的多的模型来近似，导致了KL弥散和难以训练的问题。在本篇论文中，作者将训练过程拆分为两个阶段：第一个阶段负责学习通过自编码(AE)将离散的文本转换为连续的embedding；第二个阶段学习通过重构编码得到的embedding来泛化隐含表示。这样一来，通过单独训练一个VED模型来对高斯噪声进行变化，进而采样得到隐变量，能够得到一个更加灵活的分布。</p>
<h3 id="BBQ-Networks-Efficient-Exploration-in-Deep-Reinforcement-Learning-for-Task-Oriented-Dialogue-Systems"><a href="#BBQ-Networks-Efficient-Exploration-in-Deep-Reinforcement-Learning-for-Task-Oriented-Dialogue-Systems" class="headerlink" title="BBQ-Networks: Efficient Exploration in Deep Reinforcement Learning for Task-Oriented Dialogue Systems"></a>BBQ-Networks: Efficient Exploration in Deep Reinforcement Learning for Task-Oriented Dialogue Systems</h3><h3 id="Personalizing-a-Dialogue-System-with-Transfer-Reinforcement-Learning"><a href="#Personalizing-a-Dialogue-System-with-Transfer-Reinforcement-Learning" class="headerlink" title="Personalizing a Dialogue System with Transfer Reinforcement Learning"></a>Personalizing a Dialogue System with Transfer Reinforcement Learning</h3><pre><code>It is difficult to train a personalized task-oriented dialogue system because the data collected from each individual is often insufficient. Personalized dialogue systems trained on a small dataset can overfit and make it difficult to adapt to different user needs. One way to solve this problem is to consider a collection of multiple users&apos; data as a source domain and an individual user&apos;s data as a target domain, and to perform a transfer learning from the source to the target domain. By following this idea, we propose &quot;PETAL&quot;(PErsonalized Task-oriented diALogue), a transfer-learning framework based on POMDP to learn a personalized dialogue system. The system first learns common dialogue knowledge from the source domain and then adapts this knowledge to the target user. This framework can avoid the negative transfer problem by considering differences between source and target users. The policy in the personalized POMDP can learn to choose different actions appropriately for different users. Experimental results on a real-world coffee-shopping data and simulation data show that our personalized dialogue system can choose different optimal actions for different users, and thus effectively improve the dialogue quality under the personalized setting. 
</code></pre><h3 id="Elastic-Responding-Machine-for-Dialog-Generation-with-Dynamically-Mechanism-Selecting"><a href="#Elastic-Responding-Machine-for-Dialog-Generation-with-Dynamically-Mechanism-Selecting" class="headerlink" title="Elastic Responding Machine for Dialog Generation with Dynamically Mechanism Selecting"></a>Elastic Responding Machine for Dialog Generation with Dynamically Mechanism Selecting</h3><h3 id="RUBER-An-Unsupervised-Method-for-Automatic-Evaluation-of-Open-Domain-Dialog-Systems"><a href="#RUBER-An-Unsupervised-Method-for-Automatic-Evaluation-of-Open-Domain-Dialog-Systems" class="headerlink" title="RUBER: An Unsupervised Method for Automatic Evaluation of Open-Domain Dialog Systems"></a>RUBER: An Unsupervised Method for Automatic Evaluation of Open-Domain Dialog Systems</h3><h3 id="Addressee-and-Response-Selection-in-Multi-Party-Conversations-with-Speaker-Interaction-RNNs"><a href="#Addressee-and-Response-Selection-in-Multi-Party-Conversations-with-Speaker-Interaction-RNNs" class="headerlink" title="Addressee and Response Selection in Multi-Party Conversations with Speaker Interaction RNNs"></a>Addressee and Response Selection in Multi-Party Conversations with Speaker Interaction RNNs</h3><h3 id="Context-Aware-Conversational-Understanding-for-Intelligent-Agents-with-a-Screen"><a href="#Context-Aware-Conversational-Understanding-for-Intelligent-Agents-with-a-Screen" class="headerlink" title="Context Aware Conversational Understanding for Intelligent Agents with a Screen"></a>Context Aware Conversational Understanding for Intelligent Agents with a Screen</h3><h3 id="Conversational-Model-Adaptation-via-KL-Divergence-Regularization"><a href="#Conversational-Model-Adaptation-via-KL-Divergence-Regularization" class="headerlink" title="Conversational Model Adaptation via KL Divergence Regularization"></a>Conversational Model Adaptation via KL Divergence Regularization</h3><h3 id="Towards-a-Neural-Conversation-Model-with-Diversity-Net-Using-Determinantal-Point-Processes"><a href="#Towards-a-Neural-Conversation-Model-with-Diversity-Net-Using-Determinantal-Point-Processes" class="headerlink" title="Towards a Neural Conversation Model with Diversity Net Using Determinantal Point Processes"></a>Towards a Neural Conversation Model with Diversity Net Using Determinantal Point Processes</h3><h3 id="Towards-Building-Large-Scale-Multimodal-Domain-Aware-Conversation-Systems"><a href="#Towards-Building-Large-Scale-Multimodal-Domain-Aware-Conversation-Systems" class="headerlink" title="Towards Building Large Scale Multimodal Domain-Aware Conversation Systems"></a>Towards Building Large Scale Multimodal Domain-Aware Conversation Systems</h3><h3 id="Exploring-Implicit-Feedback-for-Open-Domain-Conversation-Generation"><a href="#Exploring-Implicit-Feedback-for-Open-Domain-Conversation-Generation" class="headerlink" title="Exploring Implicit Feedback for Open Domain Conversation Generation"></a>Exploring Implicit Feedback for Open Domain Conversation Generation</h3><h3 id="Emotional-Chatting-Machine-Emotional-Conversation-Generation-with-Internal-and-External-Memory"><a href="#Emotional-Chatting-Machine-Emotional-Conversation-Generation-with-Internal-and-External-Memory" class="headerlink" title="Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory"></a>Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory</h3><h3 id="Customized-Nonlinear-Bandits-for-Online-Response-Selection-in-Neural-Conversation-Models"><a href="#Customized-Nonlinear-Bandits-for-Online-Response-Selection-in-Neural-Conversation-Models" class="headerlink" title="Customized Nonlinear Bandits for Online Response Selection in Neural Conversation Models"></a>Customized Nonlinear Bandits for Online Response Selection in Neural Conversation Models</h3><h3 id="A-Knowledge-Grounded-Neural-Conversation-Model"><a href="#A-Knowledge-Grounded-Neural-Conversation-Model" class="headerlink" title="A Knowledge-Grounded Neural Conversation Model"></a>A Knowledge-Grounded Neural Conversation Model</h3><p>propose a knowledge grounded approach which infuses the output utterance with factual information relevant to the conversational context without slot filling.</p>
<p>The neural architecture of the knowledge grounded model which uses a set of external world facts to augment the output utterance generated bt the model. Instead of just having a set of facts to augment the conversation, a richer way could be to use knowledge graphs or commonsense knowledge bases which consist of [entity-relation-entity] triples</p>
<p>proposed a knowledge grounded neural conversation model[3], where the research is aiming at combining conversational dialogs with task-oriented knowledge using unstructured data such as Twitter data for conversation and Foursquare data for external knowledge. However, the task is still limited to a restaurant information service, and has not yet been tested with a wide variety of dialog tasks.</p>
<h3 id="CoChat-Enabling-Bot-and-Human-Collaboration-for-Task-Completion"><a href="#CoChat-Enabling-Bot-and-Human-Collaboration-for-Task-Completion" class="headerlink" title="CoChat: Enabling Bot and Human Collaboration for Task Completion"></a>CoChat: Enabling Bot and Human Collaboration for Task Completion</h3><p> propose a memory-enhanced hierarchical RNN (MemHRNN) to handle the one-shot learning challenges caused by instantly introducing new actions in CoChat.</p>
<h1 id="aaai2019"><a href="#aaai2019" class="headerlink" title="aaai2019"></a>aaai2019</h1><h2 id="related-work"><a href="#related-work" class="headerlink" title="related work"></a>related work</h2><p>Why social bots?<br>• Maximize user engagement by generating enjoyable and more human-like conversations<br>• Help reduce user frustration<br>• Influence dialogue research in general<br>(social bot papers often cited in task-completion dialogue papers)</p>
<p>• 2010: Response retrieval system (IR) [Jafarpour+ 10]<br>• 2011: Response generation using Statistical Machine Translation<br>(phrase-based MT) [Ritter+ 11]<br>• 2015: First neural response generation systems (RNN, seq2seq)<br>[Sordoni+ 15; Vinyals &amp; Le 15; Shang+ 15]</p>
<p>Similar to sequence models in Neural Machine Translation (NMT), summarization, etc. Uses either RNN, LSTM, GRU, etc.<br>Source:conversation history.<br>Target:response.</p>
<p>Blandness problem: cause and remedies Common MLE objective (maximum likelihood)<br>[Li+ 16a]提出Mutual Information for Neural Network Generation(Mutual information objective)</p>
<p>consistency problem: </p>
<ul>
<li>Personalized Response Generation [Li+ 2016b]</li>
<li>Personal modeling as multi-task learning [Luan+ 17] </li>
<li>Improving personalization with multiple losses [Al-Rfou+ 16]</li>
</ul>
<p>Long conversational context problem:</p>
<ul>
<li>It can be challenging for LSTM/GRU to encode very long context (i.e. more than 200 words: [Khandelwal+ 18]) </li>
<li>Hierarchical Encoder-Decoder (HRED) <a href="Encodes:utterance (word by word" target="_blank" rel="external">Serban+ 16</a> + conversation (turn by turn))</li>
<li>Hierarchical Latent Variable Encoder-Decoder (VHRED) [Serban+ 17] （Adds a latent variable to the decoder，and Trained by maximizing variational lower-bound on the log-likelihood）which was Related to persona model [Li+ 2016b]:Deals with 1-N problem, but unsupervisedly.</li>
</ul>
<p>Grounded problem: A Knowledge-Grounded Neural Conversation Model [Ghazvininejad+ 17] or Conversations around images e.g.,Q-As [Das+ 16] or chat [Mostafazadeh+ 17] or Grounding: affect [Huber+ 18] </p>
<p>DSTC7 Challenge: Knowledge-Grounded Conversation（“Sentence Generation” track (61 registrants as of June) Registration link: <a href="http://workshop.colips.org/dstc7/call.html）" target="_blank" rel="external">http://workshop.colips.org/dstc7/call.html）</a></p>
<h3 id="Emergence-of-reinforcement-learning-RL-for-E2E-dialogue"><a href="#Emergence-of-reinforcement-learning-RL-for-E2E-dialogue" class="headerlink" title="Emergence of reinforcement learning (RL) for E2E dialogue"></a>Emergence of reinforcement learning (RL) for E2E dialogue</h3><p> Tries to promote long-term dialogue success</p>
<ul>
<li>REINFORCE algorithm [Williams+ 92]</li>
</ul>
<p>Reward functions:</p>
<ol>
<li><p>Ease of answering:-Pr</p>
</li>
<li><p>Information flow:-logSigmoidcos</p>
</li>
<li><p>Meaningfulness:logP+logP</p>
</li>
</ol>
<p>Survey on dialogue datasets [Serban+ 15]</p>
<p>Evaluate problem：</p>
<ol>
<li><p>Human evaluation (crowdsourcing)</p>
</li>
<li><p>automatic:</p>
</li>
</ol>
<ul>
<li>Machine-Translation-Based Metrics:BLEU [Papineni+ 02]: ngram overlap metric、NIST [Doddington+ 02]（Seldom used in dialogue, but copes with blandness issue<br>• Considers info gain of each ngram: score(interesting calculation) &gt;&gt; score(of the)）、METEOR（Accounts for synonyms, paraphrases, etc.）</li>
</ul>
<ol>
<li>Trainable Metric<br>• Towards an automatic turning test [Lowe+ 17]: ADEM: Metric based on hierarchical RNN (VHRED)</li>
</ol>
<ol>
<li>problem:</li>
</ol>
<p>Dialogue task:“How NOT to evaluate dialogue systems” [Liu+ 16] </p>
<p>But same problem even for Translation task<br>[Graham +15]</p>
<h2 id="motivation"><a href="#motivation" class="headerlink" title="motivation"></a>motivation</h2><ul>
<li>1.Challenge: The blandness problem</li>
<li>2.Challenge: The consistency problem</li>
<li>3.Challenge: Long conversational context</li>
<li>4.Challenge: Grounded</li>
<li>5.Reward functions:</li>
</ul>
<ol>
<li><p>Ease of answering:-Pr</p>
</li>
<li><p>Information flow:-logSigmoidcos</p>
</li>
<li><p>Meaningfulness:logP+logP</p>
</li>
</ol>
<ul>
<li>6.Datasets</li>
<li>7.Evaluate</li>
</ul>
<p>in a netshell： </p>
<ul>
<li>MLE causes blandness (mitigated by MMI)</li>
<li>Evaluation metrics (BLEU, METEOR, etc.) reliable only on large datasets➡️expensive for optimization (e.g., sequence-level training [Ranzato+ 15])</li>
<li>RL reward functions currently too ad-hoc</li>
</ul>
<h2 id="Open-Benchmarks"><a href="#Open-Benchmarks" class="headerlink" title="Open Benchmarks"></a>Open Benchmarks</h2><ul>
<li>Alexa Challenge (2017-)</li>
</ul>
<p>–Academic competition, 15 sponsored teams in 2017, 8 in 2018</p>
<p>– $250,000 research grant (2018)</p>
<p>– Proceedings [Ram+ 17]</p>
<ul>
<li><p>Dialogue System Technology Challenge (DSTC) (2013-) (formerly Dialogue State Tracking Challenge)<br>Focused this year on grounded conversation: Visual-Scene [Hori +18], background article [Galley +18]</p>
</li>
<li><p>Conversational Intelligence Challenge (ConvAI) (2017-)<br>Focused this year on personalized chat (FB Persona-Chat dataset)</p>
</li>
</ul>
<h1 id="code"><a href="#code" class="headerlink" title="code"></a>code</h1><p>旧hred：python hred_main.py –path=./hred_pretrain/ –w2v=./word2vec/word2vec.128d.117k.bin –emb_dim=128 –max_sent=10 –batch=32 –vsize=30000 -seshid=512 –max_word=50</p>
<p>新hred：python hred_main.py –path=./hred_pretrain/ –emb_dim=128 –max_sent=10 –batch=32 –vsize=30000 -seshid=512 –max_word=50 –emtraining –model=GRU –lr_p=5 –w2v=./word2vec/word2vec.128d.117k.bin</p>
<p>rl:python train_full_rl.py –path=./saverl_model/ –abs_dir=../fast_rl_init/hred_pretrain –ext_dir=./hred_extractor –lr_p=5 –ckpt_freq=5000 –patience=10</p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/03/07/Question-Generation/" rel="next" title="Question Generation">
                <i class="fa fa-chevron-left"></i> Question Generation
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2018/07/04/socks5-Git代理/" rel="prev" title="socks5-Git代理">
                socks5-Git代理 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="https://ooo.0o0.ooo/2017/07/01/59575381605d5.png"
               alt="唐相儒" />
          <p class="site-author-name" itemprop="name">唐相儒</p>
           
              <p class="site-description motion-element" itemprop="description">Never Let Your Fear Decide Your Future</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/目录">
                <span class="site-state-item-count">72</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1-Neural-Responding-Machine-for-Short-Text-Conversation"><span class="nav-number">1.</span> <span class="nav-text">1.Neural Responding Machine for Short-Text Conversation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-Building-End-To-End-Dialogue-Systems-Using-Generative-Hierarchical-Neural-Network-Models"><span class="nav-number">2.</span> <span class="nav-text">2.Building End-To-End Dialogue Systems Using Generative Hierarchical Neural Network Models</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2-A-Hierarchical-Latent-Variable-Encoder-Decoder-Model-for-Generating-Dialogues"><span class="nav-number">3.</span> <span class="nav-text">2.A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3-Hierarchical-recurrent-attention-network-for-response-generation"><span class="nav-number">4.</span> <span class="nav-text">3.Hierarchical recurrent attention network for response generation.</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-Multiresolution-Recurrent-Neural-Networks-An-Application-to-Dialogue-Response-Generation"><span class="nav-number">5.</span> <span class="nav-text">4.Multiresolution Recurrent Neural Networks: An Application to Dialogue Response Generation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5-AN-ABSTRACTIVE-APPROACH-TO-QUESTION-ANSWERING"><span class="nav-number">6.</span> <span class="nav-text">5.AN ABSTRACTIVE APPROACH TO QUESTION ANSWERING</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#6-Query-and-Output-Generating-Words-by-Querying-Distributed-Word-Representations-for-Paraphrase-Generation"><span class="nav-number">7.</span> <span class="nav-text">6.Query and Output: Generating Words by Querying Distributed Word Representations for Paraphrase Generation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#7-2017AAAITopic-Aware-Neural-Response-Generation"><span class="nav-number">8.</span> <span class="nav-text">7.2017AAAITopic Aware Neural Response Generation</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#8-How-to-Make-Context-More-Useful-An-Empirical-Study-on-Context-Aware-Neural-Conversational-Models"><span class="nav-number">9.</span> <span class="nav-text">8.How to Make Context More Useful?An Empirical Study on Context-Aware Neural Conversational Models</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#统计行数方法"><span class="nav-number">10.</span> <span class="nav-text">统计行数方法</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#统计轮数方法"><span class="nav-number">11.</span> <span class="nav-text">统计轮数方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Dialogue-Act-Sequence-Labeling-Using-Hierarchical-Encoder-with-CRF"><span class="nav-number">11.0.1.</span> <span class="nav-text">Dialogue Act Sequence Labeling Using Hierarchical Encoder with CRF</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Eliciting-Positive-Emotion-through-Affect-Sensitive-Dialogue-Response-Generation-A-Neural-Network-Approach"><span class="nav-number">11.0.2.</span> <span class="nav-text">Eliciting Positive Emotion through Affect-Sensitive Dialogue Response Generation: A Neural Network Approach</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Augmenting-End-to-End-Dialogue-Systems-with-Commonsense-Knowledge"><span class="nav-number">11.0.3.</span> <span class="nav-text">Augmenting End-to-End Dialogue Systems with Commonsense Knowledge</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Improving-Variational-Encoder-Decoders-in-Dialogue-Generation"><span class="nav-number">11.0.4.</span> <span class="nav-text">Improving Variational Encoder-Decoders in Dialogue Generation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#BBQ-Networks-Efficient-Exploration-in-Deep-Reinforcement-Learning-for-Task-Oriented-Dialogue-Systems"><span class="nav-number">11.0.5.</span> <span class="nav-text">BBQ-Networks: Efficient Exploration in Deep Reinforcement Learning for Task-Oriented Dialogue Systems</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Personalizing-a-Dialogue-System-with-Transfer-Reinforcement-Learning"><span class="nav-number">11.0.6.</span> <span class="nav-text">Personalizing a Dialogue System with Transfer Reinforcement Learning</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Elastic-Responding-Machine-for-Dialog-Generation-with-Dynamically-Mechanism-Selecting"><span class="nav-number">11.0.7.</span> <span class="nav-text">Elastic Responding Machine for Dialog Generation with Dynamically Mechanism Selecting</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RUBER-An-Unsupervised-Method-for-Automatic-Evaluation-of-Open-Domain-Dialog-Systems"><span class="nav-number">11.0.8.</span> <span class="nav-text">RUBER: An Unsupervised Method for Automatic Evaluation of Open-Domain Dialog Systems</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Addressee-and-Response-Selection-in-Multi-Party-Conversations-with-Speaker-Interaction-RNNs"><span class="nav-number">11.0.9.</span> <span class="nav-text">Addressee and Response Selection in Multi-Party Conversations with Speaker Interaction RNNs</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Context-Aware-Conversational-Understanding-for-Intelligent-Agents-with-a-Screen"><span class="nav-number">11.0.10.</span> <span class="nav-text">Context Aware Conversational Understanding for Intelligent Agents with a Screen</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Conversational-Model-Adaptation-via-KL-Divergence-Regularization"><span class="nav-number">11.0.11.</span> <span class="nav-text">Conversational Model Adaptation via KL Divergence Regularization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Towards-a-Neural-Conversation-Model-with-Diversity-Net-Using-Determinantal-Point-Processes"><span class="nav-number">11.0.12.</span> <span class="nav-text">Towards a Neural Conversation Model with Diversity Net Using Determinantal Point Processes</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Towards-Building-Large-Scale-Multimodal-Domain-Aware-Conversation-Systems"><span class="nav-number">11.0.13.</span> <span class="nav-text">Towards Building Large Scale Multimodal Domain-Aware Conversation Systems</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Exploring-Implicit-Feedback-for-Open-Domain-Conversation-Generation"><span class="nav-number">11.0.14.</span> <span class="nav-text">Exploring Implicit Feedback for Open Domain Conversation Generation</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Emotional-Chatting-Machine-Emotional-Conversation-Generation-with-Internal-and-External-Memory"><span class="nav-number">11.0.15.</span> <span class="nav-text">Emotional Chatting Machine: Emotional Conversation Generation with Internal and External Memory</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Customized-Nonlinear-Bandits-for-Online-Response-Selection-in-Neural-Conversation-Models"><span class="nav-number">11.0.16.</span> <span class="nav-text">Customized Nonlinear Bandits for Online Response Selection in Neural Conversation Models</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#A-Knowledge-Grounded-Neural-Conversation-Model"><span class="nav-number">11.0.17.</span> <span class="nav-text">A Knowledge-Grounded Neural Conversation Model</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#CoChat-Enabling-Bot-and-Human-Collaboration-for-Task-Completion"><span class="nav-number">11.0.18.</span> <span class="nav-text">CoChat: Enabling Bot and Human Collaboration for Task Completion</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#aaai2019"><span class="nav-number">12.</span> <span class="nav-text">aaai2019</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#related-work"><span class="nav-number">12.1.</span> <span class="nav-text">related work</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Emergence-of-reinforcement-learning-RL-for-E2E-dialogue"><span class="nav-number">12.1.1.</span> <span class="nav-text">Emergence of reinforcement learning (RL) for E2E dialogue</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#motivation"><span class="nav-number">12.2.</span> <span class="nav-text">motivation</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Open-Benchmarks"><span class="nav-number">12.3.</span> <span class="nav-text">Open Benchmarks</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#code"><span class="nav-number">13.</span> <span class="nav-text">code</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">唐相儒</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  


  

    
      <script id="dsq-count-scr" src="https://.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://yoursite.com/2018/06/30/暑期工作icst/';
          this.page.identifier = '2018/06/30/暑期工作icst/';
          this.page.title = '暑期工作icst';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  





  





  






  





  

  

  

  





</body>
</html>
