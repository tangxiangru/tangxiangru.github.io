<!doctype html>



  


<html class="theme-next muse use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="google-site-verification" content="googleb849f8ce9353f945.html" />













  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="欢迎戳进" />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="KBQA: Learning Question Answering over QA Corpora and Knowledge Bases">
<meta property="og:type" content="article">
<meta property="og:title" content="kbqa">
<meta property="og:url" content="http://yoursite.com/2017/09/03/知识图谱探索/index.html">
<meta property="og:site_name" content="唐相儒的博客">
<meta property="og:description" content="KBQA: Learning Question Answering over QA Corpora and Knowledge Bases">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/e9024pz9VqXVclchRIJrZn8WGBejCdShxb0IiamXUqfKfmTu3R7aj8Rc0DnB4KJaLDUEf3b4XROjeYk6rxrJHuQ/640?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7XjKPtrR2h5pXCjgSia8aQibJoZbbM1kB6eGg527VYuXv6fcplCzaQhQhw/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7XgnHYhuhlOic9jHg6LzcJuuMeyibGibXhiaJVATNGq4YtYoc5yaNMhLiakuA/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/e9024pz9VqXVclchRIJrZn8WGBejCdShxb0IiamXUqfKfmTu3R7aj8Rc0DnB4KJaLDUEf3b4XROjeYk6rxrJHuQ/640?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7XvwNWS788CWYib3VoicxaXhr3K6icKoE4GyRcsNGdxtz5CDFEWhnsAKWrA/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7XjpDk42SoHwjM4sG85CzHCy4EiaNSpPdE1p7R0vF80lS2HW8lWQialhRQ/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7XvbI6e4ytEQMmRicYnoo3zUKhoibibdpgJTOiacUrqnEHjSVD2ibcZxyWz1w/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7X67gib7FwOVJERJJ9lQ3nOs6x1Kvgx5kFsKCicrKCGDXzibZG9Shxaa1Aw/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7XzRQkJSs4e2n9F4c7cBY5ZV86qbsb9W382fzCfvJZhFmlg5y39EuytQ/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7XJKzibqiaUv2YibSrdibSdKUicYjD3hWwM5MR0iawgsjRJyZSpTubA82kjsMA/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7XicNLwwuIdejicAgVtkttNOpTb6fbfHwric6uia9bAMqPeXIjVBkn9F7NvA/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7Xe2lavHXpBUw2dIAyzZTqDsXl3D1IYQAoZEl7EZeBespOWLQIww6Bgw/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7XGujoqbWZZwB05yMKb8N3Dk3aJ0J457K3OcqJK1UtXWzpoq0p6KqkSw/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7X9aKlY9lKZhW0Q27zZk4dZibZan8K3icYqr2M6icBcV1pXEdlTa2aaYW8Q/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7XRDwaxfSZ4qQpiaXJueqqpVX0C3dqIH3evG1ia19HdHs8KLib7oH38oGmA/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7X1kp6ad7gIvR2iaAfORthD4biaPFqxpDiatTtufbe55ty5uG4AJhaDqctA/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7X5Xia0ZbWV4aGumqNa2UTfgX20YPibfraryKEyMWnAZicfvasUU3843EKA/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7XIK80icnz1HAviajMIFzBzm0b2TVhjvz85ZNTVgVf8jlHOENbjKsh5tdQ/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglEDE6UHM1WiaZshsNAl8RgNHbPtic2MsuGImsG1kYZ4lcuzSbMHXFC6x6lRRIWAPxen8EVztiaU9ycQ/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglEDE6UHM1WiaZshsNAl8RgNT3PqIdJYaH5RriaCc7TmpsGq0o0k8tCpbjTlOgmb60JO6YVItZFlthA/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglEDE6UHM1WiaZshsNAl8RgNFBssXsZAQbd5gs0h7l4WFykIUBHBXsibzRVAHLnZj8w0eOJRjo5bLBA/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglEDE6UHM1WiaZshsNAl8RgNEywLnRcUJpXXVFZCHiaDBLqNl6w4uPaJOMlV5jgwCdxFrunFBDcEFYg/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglEDE6UHM1WiaZshsNAl8RgNcDicR8tdchiaetoLDicnoLcdZ4DdC64yBrmnVqqicAzDbPDX8Ku1euFSTQ/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglEDE6UHM1WiaZshsNAl8RgNRXYcxKEyQ30JbyFUqE8H4hEffa5Rd4NSq9IhjhxE8OAchj3pfyw48w/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglEDE6UHM1WiaZshsNAl8RgNYSsuzCqKggf1MthEhaINftibiax0hT9Jsyib333x2Eb3hxXacY5UibEiazw/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglEDE6UHM1WiaZshsNAl8RgNEuMxgm2ov3mcfz0XMews4DNlCYl3CLGssCTU3HcfFGrAia2gAvicusaA/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglEDE6UHM1WiaZshsNAl8RgNtR8ysm9rBDib6Mev5quPVKSIibFT67FtAW7IZwpN0iaxp9HOhv0tYobfQ/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglEDE6UHM1WiaZshsNAl8RgNBoBNKBKfXW9ErNAHUrT2dYN5TRlcJt0C6vCFmn4uZyX1lzV8oyaDCQ/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/e9024pz9VqXVclchRIJrZn8WGBejCdShHo2RpiaTs6VnRxfLUSbEBQKn9ia4BV5Fh3GeQnCXp7kqN7eCzWmeE5UA/640?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl0RAFZqNSYfS9yWnv9SyMGabdkkecmcTrAZe6P3WFSPv0opJApQSHRYhHdAPflp7Nnsaias9oLlBQ/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl0RAFZqNSYfS9yWnv9SyMGnicrqianEKwktE33EIuY4ibQ0PpgaCibzDQfDmv7y4icbiam2zNQJHaiaXN8A/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl0RAFZqNSYfS9yWnv9SyMGwbxZz3eVTjKhyW5eibMma3c1icicYRibgAgwcnRKI5XfXz72CpibqWYoIoA/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl0RAFZqNSYfS9yWnv9SyMGbrJpk20mcYHz8uLTSb6JUiatYGZl30lW0HEh6S9aWErJxURkSsSEscw/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgm2k8uyM8BYwAMKte3FoBuEt1caDndgYIpeq28tBrojLE2T86YpnibMLMVlmcEaA2UUwIbldUc2aSQ/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:image" content="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgm2k8uyM8BYwAMKte3FoBuEiaiagwhfdBpx7Ovu9kbGFOHe1eHxX2h6nicAA0bEtmCsLb8uzlHnWQsIg/0.png?tp=webp&wxfrom=5&wx_lazy=1">
<meta property="og:updated_time" content="2017-09-29T10:35:56.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="kbqa">
<meta name="twitter:description" content="KBQA: Learning Question Answering over QA Corpora and Knowledge Bases">
<meta name="twitter:image" content="http://mmbiz.qpic.cn/mmbiz_png/e9024pz9VqXVclchRIJrZn8WGBejCdShxb0IiamXUqfKfmTu3R7aj8Rc0DnB4KJaLDUEf3b4XROjeYk6rxrJHuQ/640?tp=webp&wxfrom=5&wx_lazy=1">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2017/09/03/知识图谱探索/"/>





  <title> kbqa | 唐相儒的博客 </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  














  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">唐相儒的博客</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/首页" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-ban"></i> <br />
            
            博客首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-hand-peace-o"></i> <br />
            
            文章分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/目录" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            文章归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/标签" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sign-language"></i> <br />
            
            文章标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-map-o"></i> <br />
            
            导航
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404.html" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-asl-interpreting"></i> <br />
            
            team
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2017/09/03/知识图谱探索/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="唐相儒">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="https://ooo.0o0.ooo/2017/07/01/59575381605d5.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="唐相儒的博客">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                kbqa
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-09-03T23:21:24+08:00">
                2017-09-03
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/09/03/知识图谱探索/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/09/03/知识图谱探索/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>KBQA: Learning Question Answering over QA Corpora and Knowledge Bases</p>
<a id="more"></a>
<h1 id="知识图谱"><a href="#知识图谱" class="headerlink" title="知识图谱"></a>知识图谱</h1><p>1、实体链接————&gt;实体识别+实体消歧</p>
<p>2、关系抽取————&gt;词性标注+语法分析+依存关系树+关系分类</p>
<h1 id="KBQA"><a href="#KBQA" class="headerlink" title="KBQA"></a>KBQA</h1><p>KBQA: Learning Question Answering over QA Corpora and Knowledge Bases</p>
<h2 id="评价标准"><a href="#评价标准" class="headerlink" title="评价标准"></a>评价标准</h2><p>评价标准：回召率（Recall），精确率（Precision)），F1-Score。而对话系统的评价标准以人工评价为主，以及 BLEU 和 Perplexity。</p>
<h2 id="主流方法"><a href="#主流方法" class="headerlink" title="主流方法"></a>主流方法</h2><h3 id="一、语义解析（Semantic-Parsing）"><a href="#一、语义解析（Semantic-Parsing）" class="headerlink" title="一、语义解析（Semantic Parsing）"></a>一、语义解析（Semantic Parsing）</h3><p>偏linguistic、将<strong>自然语言</strong>转化为  一系列形式化的<strong>逻辑形式（logic form）</strong>，通过对逻辑形式进行自底向上的解析，得到一种可以表达整个问题语义的逻辑形式，通过相应的查询语句（类似 lambda-Caculus）在知识库中进行查询，从而得出答案。</p>
<p>下图红色部分即逻辑形式，绿色部分 where was Obama born 为自然语言问题，蓝色部分为语义解析进行的相关操作，而形成的语义解析树的根节点则是最终的语义解析结果，可以通过查询语句直接在知识库中查询最终答案<br><img src="http://mmbiz.qpic.cn/mmbiz_png/e9024pz9VqXVclchRIJrZn8WGBejCdShxb0IiamXUqfKfmTu3R7aj8Rc0DnB4KJaLDUEf3b4XROjeYk6rxrJHuQ/640?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>原始论文解读：</p>
<p>该方法来自斯坦福 Berant J, Chou A, Frostig R的Semantic Parsing on Freebase from Question-Answer Pairs，文章发表于2013年的EMNLP</p>
<p>1.什么是语义解析</p>
<p>知识库Freebase由大量的三元组组成，并且这些三元组的实体和实体关系都是形式化的语言</p>
<p>给定一个自然语言的问题：“Where was Obama born？”我们面临的第一个挑战，就是如何建立问题到知识库的映射？ </p>
<p><strong>语义解析</strong>的思路是通过对自然语言进行语义上的分析，转化成为一种能够让知识库“看懂”的语义表示，进而通过知识库中的知识，进行推理（Inference）查询（Query），得出答案。 </p>
<p>简而言之，语义解析要做的事情，就是将自然语言转化为一种能够让知识库“看懂”的语义表示，这种语义表示即逻辑形式（Logic Form）。</p>
<p>2.什么是逻辑形式</p>
<p>为了能够对知识库进行查询，我们需要一种能够“访问”知识库的逻辑语言，Lambda Dependency-Based Compositional Semantics (Lambda-DCS) 是一种经典的逻辑语言，它用于处理逻辑形式（在实际操作中，逻辑形式会转化 SPARQL query，可以在 Virtuoso engine 上对 Freebase 进行查询）。如果我们把知识库看作是一个数据库，那么逻辑形式（Logic Form）则可以看作是查询语句的表示。 </p>
<p>我们用表示一个逻辑形式，用表示知识库，表示实体，表示实体关系（有的也称谓语或属性）。简单而言，逻辑形式分为一元形式（unary）和二元形式（binary）。对于一个一元实体，我们可以查询出对应知识库中的实体，给定一个二元实体关系，可以查到它在知识库中所有与该实体关系相关的三元组中的实体对。并且，我们可以像数据库语言一样，进行连接 Join，求交集 Intersection 和聚合 Aggregate（如计数，求最大值等等）操作。具体来说，逻辑形式有以下形式和操作：</p>
<p><img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7XjKPtrR2h5pXCjgSia8aQibJoZbbM1kB6eGg527VYuXv6fcplCzaQhQhw/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>有了上面的定义，我们就可以把一个自然语言问题表示为一个可以在知识库中进行查询的逻辑形式</p>
<p>比如对于问句“Number of dramas starring Tom Cruise?”它对应的逻辑形式是：</p>
<p><img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7XgnHYhuhlOic9jHg6LzcJuuMeyibGibXhiaJVATNGq4YtYoc5yaNMhLiakuA/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>当自然语言问题转化为逻辑形式之后，通过相应的逻辑语言（转化为 SPARQL query）查询知识库就可以得到答案。那么，语义解析要如何把自然语言问题正确地转化为相应的逻辑形式呢？</p>
<p>3.语义解析 KB-QA 的方法框架</p>
<p>语法分析的过程可以看作是自底向上构造语法树的过程，树的根节点，就是该自然语言问题最终的逻辑形式表达。整个流程可以分为两个步骤： </p>
<p>①词汇映射：即构造底层的语法树节点。将单个自然语言短语或单词映射到知识库实体或知识库实体关系所对应的逻辑形式。我们可以通过构造一个词汇表（Lexicon）来完成这样的映射。 </p>
<p>②构建（Composition）：即自底向上对树的节点进行两两合并，最后生成根节点，完成语法树的构建。这一步有很多种方法，诸如构造大量手工规则，组合范畴语法（Combinatory Categorical Grammars，CCG）等等，而今天这篇论文，采用了最暴力的方法，即对于两个节点都可以执行上面所谈到的连接 Join，求交 Intersection，聚合 Aggregate 三种操作，以及这篇文章独创的桥接 Bridging 操作（桥接操作的具体方式稍后会提到）进行结点合并。显然，这种合并方式复杂度是指数级的，最终会生成很多棵语法树，我们需要通过对训练数据进行训练，训练一个分类器，对语法树进行筛选。 </p>
<p>自然语言转化为逻辑形式的流程如下图所示：</p>
<p><img src="http://mmbiz.qpic.cn/mmbiz_png/e9024pz9VqXVclchRIJrZn8WGBejCdShxb0IiamXUqfKfmTu3R7aj8Rc0DnB4KJaLDUEf3b4XROjeYk6rxrJHuQ/640?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>上图红色部分即逻辑形式，绿色部分 where was Obama born 为自然语言问题，蓝色部分为词汇映射（Lexicon）和构建（Composition）使用的操作，最终形成的语义解析树的根节点即语义解析结果。 </p>
<p>接下来，我们还剩最后三个待解决的问题，如何训练分类器？如何构建词汇表？什么是桥接操作？ </p>
<p><strong>训练分类器</strong> ：</p>
<p>分类器的任务是计算每一种语法分析结果 d（Derivation）的概率，作者通过 discriminative log-linear model 进行 modeling，使用 Softmax 进行概率归一化，公式如下：</p>
<p><img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7XvwNWS788CWYib3VoicxaXhr3K6icKoE4GyRcsNGdxtz5CDFEWhnsAKWrA/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>其中 x 代表自然语言问题,<img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7XjpDk42SoHwjM4sG85CzHCy4EiaNSpPdE1p7R0vF80lS2HW8lWQialhRQ/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt="">是一个从语法分析结果<img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7XvbI6e4ytEQMmRicYnoo3zUKhoibibdpgJTOiacUrqnEHjSVD2ibcZxyWz1w/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt="">和 x 中提取出来的 b 维特征向量（该特征向量包含了构造该语法树所有操作的对应特征，每种操作的具体特征之后会提到）,<img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7X67gib7FwOVJERJJ9lQ3nOs6x1Kvgx5kFsKCicrKCGDXzibZG9Shxaa1Aw/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""> 是 b 维的参数向量。</p>
<p>对于训练数据问题-答案对<img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7XzRQkJSs4e2n9F4c7cBY5ZV86qbsb9W382fzCfvJZhFmlg5y39EuytQ/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt="">，最大化 log-likelihood 损失函数，通过 AdaGrad 算法（一种动态调整学习率的随机梯度下降算法）进行参数更新。</p>
<p><img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7XJKzibqiaUv2YibSrdibSdKUicYjD3hWwM5MR0iawgsjRJyZSpTubA82kjsMA/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>可以看出特征向量的训练实际上是一种弱监督训练（准确的说是一种远程监督，DistantSupervison）。</p>
<p><strong>构建词汇表</strong> ：</p>
<p>词汇表即自然语言与知识库实体或知识库实体关系的单点映射，这一操作也被称为对齐（Alignment）。我们知道自然语言实体到知识库实体映射相对比较简单，比如将“Obama was also born in Honolulu.”中的实体 Obama 映射为知识库中的实体 BarackObama，可以使用一些简单的字符串匹配方式进行映射。 </p>
<p>但是要将自然语言短语如“was also born in”映射到相应的知识库实体关系，如 PlaceOfBirth， 则较难通过字符串匹配的方式建立映射。怎么办呢？没错，我们可以进行统计。直觉上来说，在文档中，如果有较多的实体对（entity1，entity2）作为主语和宾语出现在 was also born in 的两侧，并且，在知识库中，这些实体对也同时出现在包含 PlaceOfBirth 的三元组中，那么我们可以认为“was also born in”这个短语可以和 PlaceOfBirth 建立映射。 </p>
<p>比如（“Barack Obama”，“Honolulu”）,（“MichelleObama”，“Chicago”）等实体对在文档中经常作为“was also born in”这个短语的主语和宾语，并且它们也都和实体关系 PlaceOfBirth 组成三元组出现在知识库中。 </p>
<p>有了这样的直觉，我们再来看看这篇文章是怎么构建词汇表的，利用 ReVerbopen IE system 在 ClueWeb09（cmu的，还有12 年版本，ClueWeb12）上抽取 15 millions 个三元组构成一个数据集，如 (“Obama”, “was also born in”, “August 1961”)，可以看出三元组的实体和关系都是自然语言的形式，取出其中的一个三元组子集，对里面的每一个三元组的主语实体和宾语实体通过字符匹配的方式替换为知识库的实体，并使用 SUTime 对数据进行归一化。 </p>
<p>如(“Obama”, “was also born in”, “August 1961”) 经过预处理后转化为 (BarackObama, “was also born in”, 1961-08)。 </p>
<p>接着我们对每一个三元组中的自然语言短语两边的实体对（entity1，entity2）进行统计，注意，由于自然语言短语 r1 知识库实体关系 r2 的对应关系是多对多的，比如“was also born in”可能对应 PlaceOfBirth，也可能对应 DateOfBrith，我们需要对每一个 r1 进行区分，我们可以通过知识库查询到每一个实体的类型（type），比如 1961-08 的类型是 date 而 honolulu 的类型是 place，我们对 r1 两边的实体类型进行查询可以得到主语实体的类型 t1 和宾语实体的类型 t2，因此 r1 可以进一步表示为 r[t1,t2]，我们对其所在三元组两边的实体进行统计，得到实体对集合F(r[t1,t2])。 </p>
<p>同样的，通过对知识库进行统计，对每一个知识库三元组中的实体关系 r2 也统计其两边的实体，可以得到实体对集合 F(r2)，通过比较集合 F(r[t1,t2]) 和集合 F(r2) 类似 Jaccard 距离（集合交集元素数目比集合并集元素个数）这样的特征来确定是否建立词汇映射，如下图所示：</p>
<p><img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7XicNLwwuIdejicAgVtkttNOpTb6fbfHwric6uia9bAMqPeXIjVBkn9F7NvA/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>图中绿色字体为 r1，蓝色字体为 r2。作者定义了词汇映射操作的三种特征（用于训练分类器），对齐特征（Alignmentfeatures），文本相似度特征（Textsimilarity features），和词汇化特征（Lexicalizedfeatures），具体内容如下表所示：</p>
<p><img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7Xe2lavHXpBUw2dIAyzZTqDsXl3D1IYQAoZEl7EZeBespOWLQIww6Bgw/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>其中文本相似度特征中的 s2 指 r2 的 freebase name。 </p>
<p>在实际使用中，我们可以通过词性标注（POS）和命名实体识别（NER）来确定哪些短语和单词需要被词汇映射（Lexicon），从而忽略对一些 skippedwords 进行词汇映射。并且，作者还建立了 18 种手工规则，对问题词（questionwords）进行逻辑形式的直接映射，如“where，how many”映射为 Type.Location 和 Count。 </p>
<p><strong>桥接操作</strong> ：</p>
<p>完成词汇表的构建后，仍然存在一些问题。比如，对于 go，have，do 这样的轻动词（light verb）难以直接映射到一个知识库实体关系上，其次，有些知识库实体关系极少出现，不容易通过统计的方式找到映射方式，还有一些词比如 actress 实际上是两个知识库实体关系进行组合操作后的结果 (actor ∩ gender.female)。 </p>
<p>作者最后提到这个问题有希望通过在知识库上进行随机游走 Random walk 或者使用马尔科夫逻辑 Markov logic 解决，因此我们需要一个补丁，需要找到一个额外的二元关系来将当前的逻辑形式连接起来，那就是桥接。 </p>
<p>这里举个具体的例子，比如“Which college did Obama go to?” 假设“Obama” 和 “college” 可被词汇映射映射为 BarackObama 和 Type.University，这里”go to” 却难以找到一个映射，事实上，这里我们需要去寻找一个中间二元关系（即Education）使得上面的句子可以被解析为 (Type.University ∩ Education.BarackObama)，如下图所示：</p>
<p><img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7XGujoqbWZZwB05yMKb8N3Dk3aJ0J457K3OcqJK1UtXWzpoq0p6KqkSw/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>具体来说，给定两个类型（type）分别为 t1 和 t2 的一元逻辑形式 z1 和 z2，我们需要找到一个二元逻辑形式 b，在 b 对应的实体对类型满足 (t1,t2) 的条件下生成逻辑形式<img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7X9aKlY9lKZhW0Q27zZk4dZibZan8K3icYqr2M6icBcV1pXEdlTa2aaYW8Q/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt="">，这就是桥接，由于这里有类型的限制，所以我们可以在知识库中相邻的逻辑关系中暴力搜索符合条件的二元关系 b。（注：在论文中还提到了另外两种需要进行桥接的场景，这里我们则不再赘述）。</p>
<p>同样的，作者也为桥接操作定义了相应的特征（为了分类器的训练），定义如下表所示：</p>
<p><img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7XRDwaxfSZ4qQpiaXJueqqpVX0C3dqIH3evG1ia19HdHs8KLib7oH38oGmA/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>对于构建（composition）的其他三种操作，连接Join，求交集Intersection和聚合Aggregate，作者也定义了相应的特征（为了分类器的训练），如下表所示：</p>
<p><img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7X1kp6ad7gIvR2iaAfORthD4biaPFqxpDiatTtufbe55ty5uG4AJhaDqctA/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>至此，语法树的构建，分类器的训练，和分类器的输入——特征向量的构造方式我们都已经介绍完毕。最后我们再简单的介绍一下实验和实验结果。</p>
<p>4.实验结果</p>
<p>由于语义解析树的构建方式是指数级的，因此，在训练和测试的时候，作者执行了标准的自底向上的集束分析器（Beam-based bottom-up parser）。在这篇论文之前，KB-QA 流行的数据集是由 Cai and Yates (2013) 构建的 Free917，该数据集只包含了 917 组问题答案对，因此，作者构建了一个更大的 benchmark 数据集 WebQuestion，包含了 5810 组问题答案对，该数据集的构建方式我在揭开知识库问答 KB-QA 的面纱·简介篇中进行了简单介绍。 </p>
<p>作者测试了仅使用Alignment和Bridging以及都使用下的正确率，如下表所示：</p>
<p><img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7X5Xia0ZbWV4aGumqNa2UTfgX20YPibfraryKEyMWnAZicfvasUU3843EKA/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>我们可以看出传统的语义解析方法还是存在大量的手工规则，也涉及到了一些 linguistic 的知识，对于没有传统 NLP 先验知识的朋友可能理解起来会稍微困难一些。 </p>
<p>however，该方法有些什么缺陷？ </p>
<p>首先，词汇映射是整个算法有效（work）的基点，然而这里采用的词汇映射（尤其是关系映射）是基于比较简单的统计方式，对数据有较大依赖性。最重要的是，这种方式无法完成自然语言短语到复杂知识库关系组合的映射（如 actress 映射为<img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgmQ5ps2EwCKM0YrPHGSlU7XIK80icnz1HAviajMIFzBzm0b2TVhjvz85ZNTVgVf8jlHOENbjKsh5tdQ/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt="">。 </p>
<p>其次，在答案获取的过程中，通过远程监督学习训练分类器对语义树进行评分，注意，这里的语义树实际的组合方式是很多的，要训练这样一个强大的语义解析分类器，需要大量的训练数据。我们可以注意到，无论是 Free917 还是 WebQuestion，这两个数据集的问题-答案对都比较少。 </p>
<p>其他代表论文：</p>
<p>Berant J, Chou A, Frostig R, et al. Semantic Parsing on Freebase from Question-Answer Pairs[C]//EMNLP. 2013, 2(5): 6.</p>
<p>Cai Q, Yates A. Large-scale Semantic Parsing via Schema Matching and Lexicon Extension[C]//ACL (1). 2013: 423-433.</p>
<p>Kwiatkowski T, Choi E, Artzi Y, et al. Scaling semantic parsers with on-the-fly ontology matching[C]//In Proceedings of EMNLP. Percy. 2013.</p>
<p>Fader A, Zettlemoyer L, Etzioni O. Open question answering over curated and extracted knowledge bases[C]//Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining. ACM, 2014: 1156-1165.</p>
<h3 id="二、信息抽取（Information-Extraction）"><a href="#二、信息抽取（Information-Extraction）" class="headerlink" title="二、信息抽取（Information Extraction）"></a>二、信息抽取（Information Extraction）</h3><p>该类方法通过提取问题中的实体，通过在知识库中查询该实体可以得到以该实体节点为中心的<strong>知识库子图</strong>，子图中的每一个节点或边都可以作为候选答案，通过观察问题依据某些规则或模板进行信息抽取，得到问题特征向量，建立分类器通过输入问题特征向量对候选答案进行筛选，从而得出最终答案。</p>
<p>信息抽取的代表论文 </p>
<p>Yao X, Van Durme B. Information Extraction over Structured Data: Question Answering with Freebase[C]//ACL (1). 2014: 956-966。</p>
<p>1.人类的思考方式</p>
<p>想一想，如果有人问你 “what is the name of Justin Bieber brother?” ，并且给你一个知识库，你会怎么去找答案？显然，这个问题的主题（Topic）词就是 Justin Bieber，因此我们会去知识库搜索 Justin Bieber 这个实体，寻找与该实体相关的知识（此时相当于我们确定了答案的范围，得到了一些候选答案）。</p>
<p>接下来，我们去寻找和实体关系 brother 相关的实体，最后得到答案。 </p>
<p>而信息抽取的方法，其灵感就是来自于刚才我们的这种思考方式。</p>
<p>2.如何对问题进行信息抽取</p>
<p>还是这个例子，想想我们人类是怎么对这个问题进行信息抽取和推理的。首先，我们会潜意识地对这个句子结构进行分析，下图是 “what is the name of Justin Bieber brother?” 这个问句的语法依存树（Dependency tree），如果你对依存树不了解，可以把它理解成是一种句子成分的形式化描述方式。</p>
<p><img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglEDE6UHM1WiaZshsNAl8RgNHbPtic2MsuGImsG1kYZ4lcuzSbMHXFC6x6lRRIWAPxen8EVztiaU9ycQ/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>我们首先通过依存关系 nsubj (what, name) 和 prep_of (name, brother) 这两条信息知道答案是一个名字，而且这个名字和 brother 有关，当然我们此时还不能判断是否是人名。</p>
<p>进一步，通过 nn (brother, justin bieber) 这条信息我们可以根据 justin bieber 是个人，推导出他的 brother 也是个人，综合前面的信息，我们最终推理出来我们的答案应该是个人名。（注：这里 nsubj 代表名词性主语，prep_of 代表 of 介词修饰，nn 代表名词组合）当确定了最终答案是一个人名，那么我们就很容易在备选答案中筛选出正确答案了。 </p>
<p>我们刚才进行的步骤，实际上就是在对问题进行信息抽取，接下来，让我们看看这篇文章具体是怎么实施的。 </p>
<p>首先我们要提取的第一个信息就是问题词（question word，记作 qword），例如 who, when, what, where, how, which, why, whom, whose，它是问题的一个明显特征 。</p>
<p>第二个关键的信息，就是问题焦点（question fucus，记作 qfocus），这个词暗示了答案的类型，比如 name/time/place，我们直接将问题词 qword 相关的那个名词抽取出来作为 qfocus，在这个例子中，what name 中的 name 就是 qfocus。</p>
<p>第三个我们需要的信息，就是这个问题的主题词（word topic，记作 qtopic），在这个句子里 Justin Bieber 就是 qtopic，这个词能够帮助我们找到 freebase 中相关的知识，我们可以通过命名实体识别（Named Entity Recognition，NER）来确定主题词，需要注意的是，一个问题中可能存在多个主题词。</p>
<p>最后，第四个我们需要提取的特征，就是问题的中心动词（question verb ，记作 qverb），动词能够给我们提供很多和答案相关的信息，比如 play，那么答案有可能是某种球类或者乐器。我们可以通过词性标注（Part-of-Speech，POS）确定 qverb。</p>
<p>通过对问题提取问题词 qword，问题焦点 qfocus，问题主题词 qtopic 和问题中心动词 qverb 这四个问题特征，我们可以将该问题的依存树转化为问题图（Question Graph），如下图所示：</p>
<p><img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglEDE6UHM1WiaZshsNAl8RgNT3PqIdJYaH5RriaCc7TmpsGq0o0k8tCpbjTlOgmb60JO6YVItZFlthA/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>具体来说，将依存树转化为问题图进行了三个操作：</p>
<p>1）将问题词 qword，问题焦点 qfocus，问题主题词 qtopic 和问题中心动词 qverb 加入相对应的节点中，如 what -&gt; qword=what。 </p>
<p>2）如果该节点是命名实体，那就把该节点变为命名实体形式，如 justin -&gt; qtopic=person （justin 对应的命名实体形式是 person）。这一步的目的是因为数据中涉及到的命名实体名字太多了，这里我们只需要区分它是人名 地名 还是其他类型的名字即可。 </p>
<p>3）删除掉一些不重要的叶子节点，如限定词（determiner，如 a/the/some/this/each 等），介词（preposition）和标点符号（punctuation）。</p>
<p> 从依存树到问题图的转换，实质是就是对问题进行信息抽取，提取出有利于寻找答案的问题特征，删减掉不重要的信息。</p>
<p>3.如何构建特征向量对候选答案进行分类</p>
<p>在候选答案中找出正确答案，实际上是一个二分类问题（判断每个候选答案是否是正确答案），我们使用训练数据问题-答案对，训练一个分类器来找到正确答案。那么分类器的输入特征向量怎么构造和定义呢？ </p>
<p>特征向量中的每一维，对应一个问题-候选答案特征。每一个问题-候选答案特征由问题特征中的一个特征，和候选答案特征的一个特征，组合（combine）而成。 </p>
<p>问题特征：我们从问题图中的每一条边 e(s,t)，抽取 4 种问题特征：s，t，s|t，和 s|e|t。如对于边 prep_of(qfocus=name，brother)，我们可以抽取这样四个特征：qfocus=what，brother，qfocus=what|brother  和 qfocus=what|prep_of|brother。 </p>
<p>候选答案特征：对于主题图中的每一个节点，我们都可以抽取出以下特征：该节点的所有关系（relation，记作 rel），和该节点的所有属性（property，如 type/gender/age）。（注：我在揭开知识库问答KB-QA的面纱1·简介篇中对知识库中属性和关系的区别进行了讲解）</p>
<p>对于 Justin Bieber 这个 topic 我们可以在知识库找到它对应的主题图，如下图所示：</p>
<p><img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglEDE6UHM1WiaZshsNAl8RgNFBssXsZAQbd5gs0h7l4WFykIUBHBXsibzRVAHLnZj8w0eOJRjo5bLBA/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>例如，对于 Jaxon Bieber 这个 topic 节点，我们可以提取出这些特征：gender=male，type=person，rel=sibling 。可以看出关系和属性都刻画了这个候选答案的特征，对判断它是否是正确答案有很大的帮助。 </p>
<p>问题-候选答案特征：每一个问题-候选答案特征由问题特征中的一个特征和候选答案特征中的一个特征，组合（combine）而成（组合记作 | ）。</p>
<p>我们希望一个关联度较高的问题-候选答案特征有较高的权重，比如对于问题-候选答案特征 qfocus=money|node type=currency（注意，这里 qfocus=money 是来自问题的特征，而 node type=currency 则是来自候选答案的特征），我们希望它的权重较高，而对于问题-候选答案特征 qfocus=money|node type=person 我们希望它的权重较低。 </p>
<p>接下来我们用 WebQuestion 作为训练数据，使用 Stanford CoreNLP 帮助我们对问题进行信息抽取。训练集中约有 3000 个问题，每个问题对应的主题图约含 1000 个节点，共计有 3 million 的节点和 7 million 种问题-候选答案特征。</p>
<p>作者用<strong>带L1 正则化的逻辑回归（logistic regression）</strong>作为分类器，训练每种问题-候选答案特征的权值（L1 正则化的逻辑回归很适合处理这种稀疏的特征向量，作者表示其效果好于感知机 Percptron 和支持向量机 SVM）。 训练完毕后，得到了 3 万个非零的特征，下表列出了部分特征和它相应的权值，可以看出问题特征和候选答案特征相关度较高时，其权值较高。</p>
<p><img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglEDE6UHM1WiaZshsNAl8RgNEywLnRcUJpXXVFZCHiaDBLqNl6w4uPaJOMlV5jgwCdxFrunFBDcEFYg/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>因此，在使用的时候，对于每一个候选答案，我们抽取出它的特征（假设有 k 个特征）后，再和问题中的每一个特征两两结合（假设有 m 个特征），那么我们就得到了 k<em>m 个问题-候选答案特征，因此我们的输入向量就是一个 k</em>m-hot（即 k*m 维为 1，其余维为 0）的 3 万维向量。 </p>
<p>在提取候选答案的特征时，我们对每个实体提取了它的关系和属性，在论文中，作者还额外提取了一个更强力的特征，即每一个关系 R 和整个问题 Q 的关联度，可表示为概率的形式 P(R|Q)。那么这个概率如何求解呢？作者采用朴素贝叶斯，backoff model（即<img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglEDE6UHM1WiaZshsNAl8RgNcDicR8tdchiaetoLDicnoLcdZ4DdC64yBrmnVqqicAzDbPDX8Ku1euFSTQ/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt="">）的思想和假设，对于<img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglEDE6UHM1WiaZshsNAl8RgNRXYcxKEyQ30JbyFUqE8H4hEffa5Rd4NSq9IhjhxE8OAchj3pfyw48w/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt="">这种复合关系，people.person.parents，也采用 backoff 的思想（即<img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglEDE6UHM1WiaZshsNAl8RgNYSsuzCqKggf1MthEhaINftibiax0hT9Jsyib333x2Eb3hxXacY5UibEiazw/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt="">）这个概率进行近似，即：<img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglEDE6UHM1WiaZshsNAl8RgNEuMxgm2ov3mcfz0XMews4DNlCYl3CLGssCTU3HcfFGrAia2gAvicusaA/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>作者通过 freebase 知识库和两个数据集分别对上面的概率进行统计估算。第一个数据集是 Berant J, Chou A, Frostig R, et al. 中 Semantic Parsing on Freebase from Question-Answer Pairs 使用到的利用 ReVerbopen IE system 在 ClueWeb09 抽取的三元组数据集，包含了 15 million 个三元组，该数据集记作 ReverbMapping，第二个数据集是含 1.2 billion 对齐对（alignment pairs）的 CluewebMapping。</p>
<p>值得一提的是，这些数据中并不直接包含知识库中的关系 rel，那么要如何去估算 P(w|r) 呢？作者采用了一个近似的办法，如果一个数据集中的三元组包含的两个实体和知识库中的关系 r 包含的两个实体一样，就认为这个三元组中存在该关系 r，计数加一。 </p>
<p>在两个数据集上分别完成统计和计算后，作者使用了 WebQuestion 进行了测试，分别计算给定每一个问题 Q，答案对应的 relation，它们的概率和其他 relation 相比，排名在 top1, top5, top10, top50, top100 和 100 之后这六种情况的百分比，如下表所示：</p>
<p><img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglEDE6UHM1WiaZshsNAl8RgNtR8ysm9rBDib6Mev5quPVKSIibFT67FtAW7IZwpN0iaxp9HOhv0tYobfQ/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>可以看出当使用 ClueWebMapping 这个超大数据集训练后，给定一个问题，每次选择概率最高的 rel 时，有 19% 的正确率。因此，作者对于主题图中的每一个候选答案，增加这样一种特征，即该候选答案对应的每一个关系 rel，其概率 P(rel|Q) 在所有关系中的排名情况（如 top1、top3、top5、top50、top100 等等），比如特征 income_relation_rank=top_3（这里因为 relation 是有方向的，所以用 income 前缀对方向加以区分)。 </p>
<p>至此，我们已经搞清楚了这篇文章方法涉及到的所有元素：问题特征，候选答案特征，每个候选答案和问题的特征向量以及分类器。最后，我们再简单介绍下实验。</p>
<p>4.论文实验与总结</p>
<p>候选答案的主题图是根据问题中的主题词确定的，而一个问题可能包含多个主题词。作者先通过命名实体识别提取问题中的所有命名实体（如果提取不到一个命名实体，则使用名词短语代替），将所有命名实体输入到 Freebase Search API 中，选取返回排名最高的作为最终的主题词，使用 Freebase Topic API 得到相应的主题图。 </p>
<p>当然使用 Freebase Search API 这个方法可能会错过真正和答案相关的主题词（topic），作者也测试了模型在真实的主题词（Gold Retrieval）下的 F1 score，结果如下： </p>
<p><img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhglEDE6UHM1WiaZshsNAl8RgNBoBNKBKfXW9ErNAHUrT2dYN5TRlcJt0C6vCFmn4uZyX1lzV8oyaDCQ/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>相比Semantic Parsing on Freebase from Question-Answer Pairs 方法在 F1-score 下有较高的提升，到达了 42.0 的 F1-score。 </p>
<p>信息抽取的办法，总体来说涉及到了不少 linguistic 的知识，比较符合人类的直觉。虽然也涉及到了很多手工和先验知识的东西，但个人认为它的思想还是很不错的。 </p>
<p>作者在构造候选答案特征时，引入了和 P(R|Q) 相关的特征，这个思路是一个很好的思路，但是对 P(R|Q) 的估计方式总体来说还是比较粗暴（比如使用 backoff），个人认为可以使用 Deep Learning 的方法进行提升。</p>
<h3 id="三、向量建模（Vector-Modeling）"><a href="#三、向量建模（Vector-Modeling）" class="headerlink" title="三、向量建模（Vector Modeling）"></a>三、向量建模（Vector Modeling）</h3><p>和信息抽取的思想比较接近，根据问题得出候选答案，把问题和候选答案都映射为分布式表达（Distributed Embedding），通过训练数据对该分布式表达进行训练，使得问题和正确答案的向量表达的得分（通常以点乘为形式）尽量高，如下图所示。模型训练完成后则可根据候选答案的向量表达和问题表达的得分进行筛选，得出最终答案。</p>
<p><img src="http://mmbiz.qpic.cn/mmbiz_png/e9024pz9VqXVclchRIJrZn8WGBejCdShHo2RpiaTs6VnRxfLUSbEBQKn9ia4BV5Fh3GeQnCXp7kqN7eCzWmeE5UA/640?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p> Question answering with subgraph embeddings（文章发表于 2014 年的 EMNLP 会议）：</p>
<p> 问题一是如何将问题和答案映射到低维空间，显然我们不能仅仅将自然语言的问题和答案进行映射，还要将知识库里的知识也映射到这个低维空间中（否则我们就只是在做 QA 而非 KB-QA 了）</p>
<p>第二个问题是，如果做过类似工作（one-shot，imgae caption，word embedding 等）的朋友应该知道，使用这种方法是需要大量数据去训练这个低维空间的分布式表达的，而 KB-QA 中的 benchmark 数据集 WebQuestion 只含有 5800 多个问题答案对，这样的数据是难以训练好这种表达的。 </p>
<p>问题的分布式表达：首先我们把自然语言问题进行向量化，作者将输入空间的维度 N 设置为字典的大小+知识库实体数目+知识库实体关系数目，对于输入向量每一维的值设置为该维所代表的单词（当然这一维也可能代表的是某个实体数目或实体关系，对于问题的向量化，这些维数都设置为 0）在问题中出现的次数（一般为 0 或 1 次），可以看出这是一种 multi-hot 的稀疏表达，是一种简化版的词袋模型（Bag-of-words model）。 </p>
<p>我们用 q 代表问题，用 Φ(q) 代表 N 维的问题向量，用矩阵 W 将 N 维的问题向量映射到 k 维的低维空间，那么问题的分布式表达即 f(q)=WΦ(q)。</p>
<p>答案的分布式表达：我们想想可以怎样对答案进行向量化，最简单的方式，就是像对问题一样的向量化方式，使用一个简化版的词袋模型。由于答案都是一个知识库实体，那么这样的表达就是一个 one-hot 的表达，显然，这种方式并没有把知识库的知识引入到我们的输入空间中。 </p>
<p>第二种方式，我们把知识库想象成一个图，图的节点代表实体，边代表实体关系。通过问题中的主题词可以定位到图中的一个节点，该节点到答案节点有一条路径，我们把该路径上的所有边（实体关系）和点（实体）都以 multi-hot 的形式存下来作为答案的输入向量。</p>
<p>我们这里只考虑一跳（hop）或者两跳的路径，如路径（barack obama, place of birth, honolulu）是一跳，路径（barack obama, people.person.place of birth, location.location.containedby, hawaii）是两跳。因此这种表示是一种 3-hot 或 4-hot 的表示。 </p>
<p>第三种方式，让我们回想一下我们在揭开知识库问答KB-QA的面纱3·信息抽取篇介绍的信息抽取的方法，对于每一个候选答案，该答案所对应的属性（type/gender 等）和关系都是能够帮助我们判断它是否是正确答案的重要信息。</p>
<p>因此我们可以把每个候选答案对应的知识库子图（1 跳或 2 跳范围）也加入到输入向量中，假设该子图包含 C 个实体和 D 个关系，那么我们最终的表达是一种 3+C+D-hot 或者 4+C+D-hot 的表达。和信息抽取方法一样，我们也对关系的方向进行区分，因此我们输入向量的大小变为字典的大小+2*（知识库实体数目+知识库实体关系数目）。</p>
<p>同样的，我们用 a 表示答案，用 Ψ(a) 表示答案的输入向量，用矩阵 W 将问题向量映射到 k 维的低维空间，答案的分布式表达即 g(a)=WΨ(a)。</p>
<p>向量得分：最后我们用一个函数表征答案和问题的得分，我们希望问题和它对应的正确答案得尽量高分，通过比较每个候选答案的得分，选出最高的，作为正确答案。得分函数定义为二者分布式表达的点乘，即s(q,a)=f(q)*g(a)。</p>
<p>上述整个流程如下图所示：</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl0RAFZqNSYfS9yWnv9SyMGabdkkecmcTrAZe6P3WFSPv0opJApQSHRYhHdAPflp7Nnsaias9oLlBQ/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>训练分布式表达：</p>
<p>对于训练数据集D，我们定义 <strong>margin-based ranking 损失函数</strong>，公式如下：<br><img src="https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl0RAFZqNSYfS9yWnv9SyMGnicrqianEKwktE33EIuY4ibQ0PpgaCibzDQfDmv7y4icbiam2zNQJHaiaXN8A/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>做过 zero-shot 或者对 SVM 了解的朋友应该对这个式子不会陌生，其中  表示负样本集  中的一个负样本（错误答案），m 是一个值为 0.1 的 margin。最小化这个损失函数，意味着我们希望正确答案和问题的得分要比任意错误答案的得分高出一个 margin。 </p>
<p>和训练 word embedding 一样，为减少计算量，我们通过采样的方式构造负样本，50% 来自随机挑选，50% 来自与问题主题词实体相连的其它路径。 </p>
<p>由于 benchmark 数据集 WebQuestion 包含的样本数过少，作者还构造了其他几个数据集： </p>
<p>Freebase：选取 freebase 中包含出现频率高于 5 次实体的三元组，得到一个知识库子集（含 2.2M 实体和 7K 关系），对于每一个三元组如（subject, type1.type2.predicate, object），我们通过自动化的方式，生成这样的问题答案对： </p>
<p>Quesiton：“What is the predicate of the type2subject?” Answer：object </p>
<p>ClueWeb Extractions：由于 Freebase 的三元组都是形式化语言，并不贴近自然语言，我们也用同样的方式将 ClueWeb 上提取出的三元组（subject, “text string”, object）通过少量模板作同样的变换（作者提取了 2M 对三元组）。 </p>
<p>这样我们就在 WebQuestion 数据集的基础上，得到了一个新的扩展数据集，该数据集的例子如下表所示：</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl0RAFZqNSYfS9yWnv9SyMGwbxZz3eVTjKhyW5eibMma3c1icicYRibgAgwcnRKI5XfXz72CpibqWYoIoA/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>可以看出，扩增版的数据集，问题大多数都是自动构造的，缺乏多样性和真实性。怎么办呢？我们希望训练数据中问题的分布式表达尽量贴近它所类似的真实问题的分布式表达。</p>
<p>因此，作者在 WikiAnswers 中抓取了 2.2M 问题（不含答案），通过问题的分类标签，将它们分为了 350k 个类簇（可以理解为每个类簇里的自然语言问题它所表达的意思是一样的）。</p>
<p>如下表所示：</p>
<p><img src="https://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgl0RAFZqNSYfS9yWnv9SyMGbrJpk20mcYHz8uLTSb6JUiatYGZl30lW0HEh6S9aWErJxURkSsSEscw/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<p>接下来我们就可以进行一个多任务学习（multi-task），让同一个类簇的问题得分较高，即s(q1,q2)=f(q1)*g(q2)，其训练方式和之前训练答案和问题得分是一样的。</p>
<p>至此，通过以上两种训练，我们的分布式表达就训练完毕了。</p>
<p>根据问题首先要确定候选答案，这里作者确定候选答案的方式和信息抽取略有不同。首先在从问题中主题词对应的知识库实体出发，通过 beam search 的方式保存10个和问题最相关的实体关系（通过把实体关系当成答案，用s(q,a)=f(q)*g(a)式子的得分作为 beam search 的排序标准）。</p>
<p>接下来选取主题词两跳范围以内的路径，且该路径必须包含这 10 个关系中的关系，将满足条件的路径的终点对应的实体作为候选答案，其中，1 跳路径的权值是 2 跳的 1.5 倍（因为 2 跳包含的元素更多）。 </p>
<p>确定完候选答案后，选取s(q,a)=f(q)*g(a)得分最高的作为最终答案。 </p>
<p>该方法在 WebQuestion 数据集上进行测试，取得了 39.2 的 F1-Score。 </p>
<p>可以看出，相比信息抽取和语义解析的方法，该方法几乎不需要任何手工定义的特征（hand- crafted features），也不需要借助额外的系统（词汇映射表，词性标注，依存树等）。</p>
<p>相对来说，比较简单，也较容易实现，能取得 39.2 的 F1-score 得分（斯坦福 13 年的语义解析方法只有 35.7）也说明了该方法的强大性。通过自动化的方式扩展数据集和多任务训练也部分解决了实验数据不足的缺点。 </p>
<p>然而，向量建模方法，是一种趋于黑盒的方法，缺少了解释性（语义解析可以将问题转化成一种逻辑形式的表达，而信息抽取构造的每一维特征的含义也是离散可见的），更重要的是，它也缺少了我们的先验知识和推理（可以看出其 F1-score 略低于 14 年使用了大量先验知识的信息抽取方法，该方法 F1-score 为 42.0），事实上，这也是现在深度学习一个比较有争议的诟病。 </p>
<p>就这篇论文的向量建模方法来说，也存在一些问题，比如对问题的向量表示采用了类似词袋模型的方法，这样相当于并未考虑问题的语言顺序（比如 “谢霆锋的爸爸是谁？” 谢霆锋是谁的爸爸？ 这两个问题用该方法得到的表达是一样的，然而这两个问题的意思显然是不同的），且训练分布式表达的模型很简单，相当于一个两层的感知机。这些问题，可以通过深度学习来解决。</p>
<p>随着深度学习的加入，KB-QA 进入了一个新的时代。下一期，我们将进入深度学习篇，由于深度学习可以对传统的三种方法都可以进行提升，因此我们打算将深度学习篇拆成 2-3 篇来进行讲解，进一步揭开 KB-QA 的面纱，敬请期待本系列后续文章。</p>
<p>其他代表论文： </p>
<p>Bordes A, Chopra S, Weston J. Question answering with subgraph embeddings[J]. arXiv preprint arXiv:1406.3676, 2014.</p>
<p>Yang M C, Duan N, Zhou M, et al. Joint Relational Embeddings for Knowledge-based Question Answering[C]//EMNLP. 2014, 14: 645-650.</p>
<p>Bordes A, Weston J, Usunier N. Open question answering with weakly supervised embedding models[C]//Joint European Conference on Machine Learning and Knowledge Discovery in Databases. Springer Berlin Heidelberg, 2014: 165-180.</p>
<p>上述方法集中在13-14年发布</p>
<h2 id="深度学习"><a href="#深度学习" class="headerlink" title="深度学习"></a>深度学习</h2><p>使用卷积神经网络对向量建模方法进行提升： </p>
<p>Dong L, Wei F, Zhou M, et al. Question Answering over Freebase with Multi-Column Convolutional Neural Networks[C]//ACL (1). 2015: 260-269. </p>
<p>使用卷积神经网络对语义解析方法进行提升： </p>
<p>Yih S W, Chang M W, He X, et al. Semantic parsing via staged query graph generation: Question answering with knowledge base[J]. 2015. </p>
<p>注：该 paper 来自微软，是 ACL 2015 年的 Outstanding paper，也是目前 KB-QA 效果最好的 paper 之一。</p>
<p>使用长短时记忆网络（Long Short-Term Memory，LSTM），卷积神经网络（Convolutional Neural Networks，CNNs）进行实体关系分类： </p>
<p>Xu Y, Mou L, Li G, et al. Classifying Relations via Long Short Term Memory Networks along Shortest Dependency Paths[C]//EMNLP. 2015: 1785-1794. </p>
<p>Zeng D, Liu K, Lai S, et al. Relation Classification via Convolutional Deep Neural Network[C]//COLING. 2014: 2335-2344.（Best paper） </p>
<p>Zeng D, Liu K, Chen Y, et al. Distant Supervision for Relation Extraction via Piecewise Convolutional Neural Networks[C]//EMNLP. 2015: 1753-1762. </p>
<p>使用记忆网络（Memory Networks），注意力机制（Attention Mechanism）进行 KB-QA： </p>
<p>Bordes A, Usunier N, Chopra S, et al. Large-scale simple question answering with memory networks[J]. arXiv preprint arXiv:1506.02075, 2015. </p>
<p>Zhang Y, Liu K, He S, et al. Question Answering over Knowledge Base with Neural Attention Combining Global Knowledge Information[J]. arXiv preprint arXiv:1606.00979, 2016. </p>
<p>以上论文几乎都使用了 Freebase 作为 knowledge base，并且在 WebQuestion 数据集上进行过测试，这里给出各种方法的效果对比图，给大家一个更加直观的感受。</p>
<p><img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgm2k8uyM8BYwAMKte3FoBuEt1caDndgYIpeq28tBrojLE2T86YpnibMLMVlmcEaA2UUwIbldUc2aSQ/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<h2 id="kbqa数据集"><a href="#kbqa数据集" class="headerlink" title="kbqa数据集"></a>kbqa数据集</h2><p>Benchmark 数据集——WebQuestion。 </p>
<p>该数据集由 Berant J, Chou A, Frostig R, et al.在 13 年的论文 Semantic Parsing on Freebase from Question-Answer Pairs 中公开。 </p>
<p><img src="http://mmbiz.qpic.cn/mmbiz_png/VBcD02jFhgm2k8uyM8BYwAMKte3FoBuEiaiagwhfdBpx7Ovu9kbGFOHe1eHxX2h6nicAA0bEtmCsLb8uzlHnWQsIg/0.png?tp=webp&amp;wxfrom=5&amp;wx_lazy=1" alt=""></p>
<h2 id="btw"><a href="#btw" class="headerlink" title="btw"></a>btw</h2><p>KBQA结合深度学习的基本思路是什么？代表方法有哪些？</p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/09/01/高恒-基于知识图谱的表示学习/" rel="next" title="高恒:基于知识图谱的表示学习">
                <i class="fa fa-chevron-left"></i> 高恒:基于知识图谱的表示学习
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/09/04/依存关系树/" rel="prev" title="依存关系树">
                依存关系树 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="https://ooo.0o0.ooo/2017/07/01/59575381605d5.png"
               alt="唐相儒" />
          <p class="site-author-name" itemprop="name">唐相儒</p>
           
              <p class="site-description motion-element" itemprop="description">Never Let Your Fear Decide Your Future</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/目录">
                <span class="site-state-item-count">57</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          

          

        </nav>

        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#知识图谱"><span class="nav-number">1.</span> <span class="nav-text">知识图谱</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#KBQA"><span class="nav-number">2.</span> <span class="nav-text">KBQA</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#评价标准"><span class="nav-number">2.1.</span> <span class="nav-text">评价标准</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#主流方法"><span class="nav-number">2.2.</span> <span class="nav-text">主流方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#一、语义解析（Semantic-Parsing）"><span class="nav-number">2.2.1.</span> <span class="nav-text">一、语义解析（Semantic Parsing）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#二、信息抽取（Information-Extraction）"><span class="nav-number">2.2.2.</span> <span class="nav-text">二、信息抽取（Information Extraction）</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#三、向量建模（Vector-Modeling）"><span class="nav-number">2.2.3.</span> <span class="nav-text">三、向量建模（Vector Modeling）</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#深度学习"><span class="nav-number">2.3.</span> <span class="nav-text">深度学习</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#kbqa数据集"><span class="nav-number">2.4.</span> <span class="nav-text">kbqa数据集</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#btw"><span class="nav-number">2.5.</span> <span class="nav-text">btw</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">唐相儒</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  






  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  


  

    
      <script id="dsq-count-scr" src="https://.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'http://yoursite.com/2017/09/03/知识图谱探索/';
          this.page.identifier = '2017/09/03/知识图谱探索/';
          this.page.title = 'kbqa';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  





  





  






  





  

  

  

  





</body>
</html>
